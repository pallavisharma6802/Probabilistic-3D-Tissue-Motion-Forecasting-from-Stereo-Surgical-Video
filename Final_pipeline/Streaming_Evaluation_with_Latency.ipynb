{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","from pathlib import Path\n","\n","import numpy as np\n","import imageio.v2 as imageio\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import cv2\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","BASE_DIR = Path(\"/content/drive/Shareddrives/TissueMotionForecasting\")\n","TRAIN_ROOT = BASE_DIR / \"scared_data\" / \"train\"\n","print(\"TRAIN_ROOT:\", TRAIN_ROOT)\n","\n","DISP_SCALE = 256.0\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8kPGF0FUfmtA","executionInfo":{"status":"ok","timestamp":1765186459044,"user_tz":360,"elapsed":21600,"user":{"displayName":"Pallavi Sharma","userId":"00480827119504929317"}},"outputId":"b8a7c746-c9d1-4f4c-85a0-e248121eaa21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Using device: cuda\n","TRAIN_ROOT: /content/drive/Shareddrives/TissueMotionForecasting/scared_data/train\n"]}]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_c, out_c):\n","        super().__init__()\n","        self.block = nn.Sequential(\n","            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),\n","            nn.ReLU(inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.block(x)\n","\n","\n","class UNet(nn.Module):\n","    def __init__(self, in_channels=3, out_channels=1):\n","        super().__init__()\n","\n","        self.enc1 = DoubleConv(in_channels, 32)\n","        self.enc2 = DoubleConv(32, 64)\n","        self.enc3 = DoubleConv(64, 128)\n","        self.enc4 = DoubleConv(128, 256)\n","\n","        self.pool = nn.MaxPool2d(2)\n","\n","        self.bottleneck = DoubleConv(256, 512)\n","\n","        self.up4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n","        self.dec4 = DoubleConv(256 + 256, 256)\n","\n","        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n","        self.dec3 = DoubleConv(128 + 128, 128)\n","\n","        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n","        self.dec2 = DoubleConv(64 + 64, 64)\n","\n","        self.up1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n","        self.dec1 = DoubleConv(32 + 32, 32)\n","\n","        self.out_conv = nn.Conv2d(32, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        e1 = self.enc1(x)\n","        e2 = self.enc2(self.pool(e1))\n","        e3 = self.enc3(self.pool(e2))\n","        e4 = self.enc4(self.pool(e3))\n","\n","        b = self.bottleneck(self.pool(e4))\n","\n","        d4 = self.up4(b)\n","        d4 = torch.cat([d4, e4], dim=1)\n","        d4 = self.dec4(d4)\n","\n","        d3 = self.up3(d4)\n","        d3 = torch.cat([d3, e3], dim=1)\n","        d3 = self.dec3(d3)\n","\n","        d2 = self.up2(d3)\n","        d2 = torch.cat([d2, e2], dim=1)\n","        d2 = self.dec2(d2)\n","\n","        d1 = self.up1(d2)\n","        d1 = torch.cat([d1, e1], dim=1)\n","        d1 = self.dec1(d1)\n","\n","        out = self.out_conv(d1)\n","        return out\n"],"metadata":{"id":"MEZuF57Qgipf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class HorizonHead(nn.Module):\n","    \"\"\"\n","    Takes:\n","      - last disparity frame D_t          [B,1,H,W]\n","      - UNet's t+5 forecast mu_5         [B,1,H,W]\n","      - horizon channel h_norm           [B,1,H,W]\n","    Concatenated: [B,3,H,W] -> predicts D_{t+h}.\n","    \"\"\"\n","    def __init__(self, in_ch=3, hidden=32):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Conv2d(in_ch, hidden, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(hidden, hidden, 3, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(hidden, 1, 1),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n"],"metadata":{"id":"nU7mXShzgket"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load UNet backbone (frozen)\n","backbone = UNet(in_channels=3, out_channels=1).to(device)\n","\n","unet_ckpt_path = BASE_DIR / \"models\" / \"unet_forecast_kf1to3_7_epochs.pth\"\n","print(\"Loading UNet from:\", unet_ckpt_path)\n","unet_state = torch.load(str(unet_ckpt_path), map_location=device)\n","backbone.load_state_dict(unet_state)\n","backbone.eval()\n","for p in backbone.parameters():\n","    p.requires_grad = False\n","\n","print(\"UNet loaded & frozen.\")\n","\n","# load HorizonHead\n","horizon_head = HorizonHead(in_ch=3, hidden=32).to(device)\n","h_ckpt_path = BASE_DIR / \"models\" / \"horizon_head_after_epoch3.pth\"\n","print(\"Loading HorizonHead from:\", h_ckpt_path)\n","h_state = torch.load(str(h_ckpt_path), map_location=device)\n","horizon_head.load_state_dict(h_state[\"state_dict\"])\n","H_MAX = h_state[\"H_MAX\"]\n","horizon_head.eval()\n","\n","print(\"HorizonHead loaded for inference. H_MAX =\", H_MAX)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvbkAr6FgnEm","executionInfo":{"status":"ok","timestamp":1765186464211,"user_tz":360,"elapsed":4962,"user":{"displayName":"Pallavi Sharma","userId":"00480827119504929317"}},"outputId":"8badb4fd-c3a8-434f-9730-5fa0431834d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading UNet from: /content/drive/Shareddrives/TissueMotionForecasting/models/unet_forecast_kf1to3_7_epochs.pth\n","UNet loaded & frozen.\n","Loading HorizonHead from: /content/drive/Shareddrives/TissueMotionForecasting/models/horizon_head_after_epoch3.pth\n","HorizonHead loaded for inference. H_MAX = 9\n"]}]},{"cell_type":"code","source":["def load_disp_float(path: Path):\n","    \"\"\"uint16 disparity PNG -> float disp (divided by DISP_SCALE).\"\"\"\n","    arr = imageio.imread(str(path)).astype(np.float32)\n","    return arr / DISP_SCALE\n","\n","def disp_to_raft_color_raft_style(disp_float):\n","    \"\"\"Match the RAFT-style coloring from step1 notebook.\"\"\"\n","    disp = np.asarray(disp_float, dtype=np.float32).copy()\n","\n","    invalid = (disp <= 0)\n","    disp[invalid] = np.nan\n","\n","    valid = np.isfinite(disp)\n","    if valid.any():\n","        vmin, vmax = np.nanpercentile(disp[valid], [5, 95])\n","    else:\n","        vmin, vmax = 0.0, 1.0\n","\n","    norm = np.clip((disp - vmin) / (vmax - vmin + 1e-6), 0.0, 1.0)\n","    norm[~valid] = 0.0\n","\n","    turbo = cm.get_cmap(\"turbo\")\n","    color = (turbo(norm)[..., :3] * 255.0).astype(np.uint8)\n","    return color\n","\n","\n","def color_gt_and_pred(gt_disp, pred_disp):\n","    \"\"\"\n","    Make GT and Pred share:\n","      - the same valid mask (gt>0)\n","      - the same vmin/vmax (from GT percentiles)\n","\n","    Returns:\n","      gt_color, pred_color: uint8 [H,W,3] images in RAFT-style 'turbo' colors.\n","    \"\"\"\n","    gt = np.asarray(gt_disp, np.float32)\n","    pred = np.asarray(pred_disp, np.float32)\n","\n","    mask = gt > 0\n","\n","    if np.any(mask):\n","        vals = gt[mask]\n","        vmin, vmax = np.percentile(vals, (5, 95))\n","        if vmax <= vmin:\n","            vmax = vmin + 1e-6\n","    else:\n","        vmin, vmax = 0.0, 1.0\n","\n","    def _colorize(d):\n","        d = np.asarray(d, np.float32)\n","        d = np.clip(d, vmin, vmax)\n","        norm = (d - vmin) / (vmax - vmin + 1e-8)\n","\n","        norm[~mask] = 0.0\n","\n","        turbo = cm.get_cmap(\"turbo\")\n","        col = turbo(norm)[..., :3]\n","        col[~mask] = 0.0\n","        return (col * 255.0).astype(np.uint8)\n","\n","    return _colorize(gt), _colorize(pred)\n","\n","\n","def latency_to_horizon(eta_ms: float, dt_ms: float, allowed_horizons=(3,5,7,9)):\n","    \"\"\"\n","    eta_ms: end-to-end display delay in ms\n","    dt_ms : frame interval in ms (e.g. 40ms for 25 fps)\n","    returns: chosen horizon h in allowed_horizons\n","    \"\"\"\n","    n0 = eta_ms / dt_ms\n","    allowed = sorted(allowed_horizons)\n","    best_h = min(allowed, key=lambda h: (abs(h - n0), -h))\n","    return best_h\n","\n","chosen_h = latency_to_horizon(eta_ms=160.0, dt_ms=20.0)\n","print(\"Example latency mapping → horizon:\", chosen_h)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pO8ndVaqgohk","executionInfo":{"status":"ok","timestamp":1765186464217,"user_tz":360,"elapsed":4,"user":{"displayName":"Pallavi Sharma","userId":"00480827119504929317"}},"outputId":"4ce5ba34-8ec2-4c9c-e00d-1cc55268c43c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Example latency mapping → horizon: 9\n"]}]},{"cell_type":"code","source":["@torch.no_grad()\n","def sample_future_with_uncertainty(ctx_tensor, h, K=5, sigma=0.02):\n","    \"\"\"\n","    ctx_tensor: [1,3,H,W] disparity context (t-2,t-1,t)\n","    h: int horizon (e.g. 3,5,7,9)\n","    K: number of MC samples\n","    sigma: noise scale in disparity units\n","\n","    Returns:\n","      mean_pred: [1,1,H,W]\n","      var_pred : [1,1,H,W]\n","    \"\"\"\n","    backbone.eval()\n","    horizon_head.eval()\n","\n","    ctx_tensor = ctx_tensor.to(device)\n","\n","    mu_5 = backbone(ctx_tensor)              # [1,1,H,W]\n","    ctx_last = ctx_tensor[:, -1:, :, :]      # [1,1,H,W]\n","\n","    h_norm = (torch.tensor(float(h), device=device) / H_MAX)\n","    h_norm = h_norm.view(1,1,1,1).expand_as(mu_5)  # [1,1,H,W]\n","\n","    preds = []\n","    for k in range(K):\n","        eps = torch.randn_like(mu_5) * sigma\n","        mu_5_perturbed = mu_5 + eps\n","        x_in = torch.cat([ctx_last, mu_5_perturbed, h_norm], dim=1)  # [1,3,H,W]\n","        pred_k = horizon_head(x_in)  # [1,1,H,W]\n","        preds.append(pred_k)\n","\n","    preds = torch.stack(preds, dim=0)   # [K,1,1,H,W]\n","    mean_pred = preds.mean(dim=0)       # [1,1,H,W]\n","    var_pred  = preds.var(dim=0, unbiased=False)  # [1,1,H,W]\n","\n","    return mean_pred, var_pred\n"],"metadata":{"id":"4uuTgKlAgr4p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import imageio.v2 as imageio\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","from IPython.display import display, clear_output\n","import time\n","\n","\n","DS_NAME   = \"dataset_4\"\n","KF_ID     = 1\n","eta_ms    = 160.0\n","dt_ms     = 20\n","H_STAR = latency_to_horizon(eta_ms, dt_ms, allowed_horizons=(3,5,7,9))\n","n0 = eta_ms / dt_ms\n","print(f\"η={eta_ms} ms, Δt={dt_ms} ms → n0={n0:.2f}, using horizon H_STAR={H_STAR}\")\n","\n","\n","K_SAMPLES = 5\n","NOISE_SIGMA = 0.1\n","STEP      = 1\n","SLEEP_SEC = 0\n","SHOW_LIVE = False\n","\n","MAX_FRAMES = 100\n","\n","disp_dir = TRAIN_ROOT / DS_NAME / f\"keyframe_{KF_ID}\" / \"data\" / \"disparity\"\n","print(\"Using disparity dir:\", disp_dir)\n","\n","disp_paths = sorted(\n","    p for p in disp_dir.glob(\"*.png\")\n","    if not p.name.startswith(\"colored\")\n",")\n","\n","num_frames_total = len(disp_paths)\n","print(\"Total disparity frames on disk:\", num_frames_total)\n","\n","num_frames = min(num_frames_total, MAX_FRAMES)\n","disp_paths = disp_paths[:num_frames]\n","print(\"Using disparity frames:\", num_frames)\n","\n","if num_frames == 0:\n","    raise RuntimeError(\"No disparity PNGs found.\")\n","\n","\n","all_disp = [load_disp_float(p) for p in disp_paths]\n","\n","\n","rgb_path = TRAIN_ROOT / DS_NAME / f\"keyframe_{KF_ID}\" / \"data\" / \"rgb.mp4\"\n","print(\"RGB video:\", rgb_path)\n","rgb_reader = imageio.get_reader(str(rgb_path), \"ffmpeg\")\n","\n","left_rgb = []\n","for i in range(num_frames):\n","    frame = rgb_reader.get_data(i)\n","    H_rgb, W_rgb, _ = frame.shape\n","    mid = H_rgb // 2\n","    left = frame[:mid, :, :]\n","    left_rgb.append(left.astype(np.uint8))\n","\n","rgb_reader.close()\n","\n","min_t = 2\n","max_t = num_frames - H_STAR - 1\n","if max_t <= min_t:\n","    raise RuntimeError(\"Sequence too short for this horizon.\")\n","print(f\"Streaming from t={min_t} to t={max_t} (step={STEP})\")\n","\n","t_center = (min_t + max_t) // 2\n","ctx_sample = [all_disp[i] for i in [t_center-2, t_center-1, t_center]]\n","gt_sample  = all_disp[t_center + H_STAR]\n","\n","frames_for_range = ctx_sample + [gt_sample]\n","all_vals = []\n","valid_union = np.zeros_like(gt_sample, dtype=bool)\n","\n","for f in frames_for_range:\n","    f = np.asarray(f, dtype=np.float32)\n","    m = f > 0\n","    if np.any(m):\n","        valid_union |= m\n","        all_vals.append(f[m])\n","\n","all_vals = np.concatenate(all_vals)\n","vmin, vmax = np.percentile(all_vals, (5, 95))\n","if vmax <= vmin:\n","    vmax = vmin + 1e-6\n","\n","print(\"Global color range vmin, vmax:\", vmin, vmax)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fHOerIOumDRL","outputId":"8fffb44c-6f11-40f4-d6d0-bdd78c7fdace","executionInfo":{"status":"ok","timestamp":1765186516284,"user_tz":360,"elapsed":52057,"user":{"displayName":"Pallavi Sharma","userId":"00480827119504929317"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["η=160.0 ms, Δt=20 ms → n0=8.00, using horizon H_STAR=9\n","Using disparity dir: /content/drive/Shareddrives/TissueMotionForecasting/scared_data/train/dataset_4/keyframe_1/data/disparity\n","Total disparity frames on disk: 728\n","Using disparity frames: 100\n","RGB video: /content/drive/Shareddrives/TissueMotionForecasting/scared_data/train/dataset_4/keyframe_1/data/rgb.mp4\n","Streaming from t=2 to t=90 (step=1)\n","Global color range vmin, vmax: 31.16796875 51.3671875\n"]}]},{"cell_type":"code","source":["video_dir = BASE_DIR / \"videos\"\n","video_dir.mkdir(parents=True, exist_ok=True)\n","\n","FPS = 10.0\n","REPEATS = 1\n","\n","video_path = video_dir / f\"stream_ds{DS_NAME}_kf{KF_ID}_h{H_STAR}.mp4\"\n","writer = imageio.get_writer(str(video_path), fps=FPS)\n","print(\"Saving streaming video to:\", video_path)"],"metadata":{"id":"JNeguv7vqC8u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765186516289,"user_tz":360,"elapsed":3,"user":{"displayName":"Pallavi Sharma","userId":"00480827119504929317"}},"outputId":"2c5f4673-195b-4428-f82d-0197c6b9b533"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving streaming video to: /content/drive/Shareddrives/TissueMotionForecasting/videos/stream_dsdataset_4_kf1_h9.mp4\n"]}]},{"cell_type":"code","source":["backbone.eval()\n","horizon_head.eval()\n","\n","for t in range(min_t, max_t, STEP):\n","\n","    ctx_indices = [t-2, t-1, t]\n","    ctx_np = np.stack([all_disp[i] for i in ctx_indices], axis=0)   # [3,H,W]\n","    rgb_ctx = [left_rgb[i] for i in ctx_indices]\n","\n","    gt_t = all_disp[t + H_STAR]                                    # [H,W]\n","    rgb_future = left_rgb[t + H_STAR]                              # RGB at t+H*\n","\n","    ctx_tensor = torch.from_numpy(ctx_np).unsqueeze(0).float().to(device)\n","    mean_pred, var_pred = sample_future_with_uncertainty(\n","        ctx_tensor, h=H_STAR, K=K_SAMPLES, sigma=NOISE_SIGMA\n","    )\n","    pred_np = mean_pred[0,0].cpu().numpy()\n","    var_np  = var_pred[0,0].cpu().numpy()\n","\n","    valid_mask = gt_t > 0\n","\n","    if np.any(valid_mask):\n","        abs_err = np.abs(pred_np - gt_t)\n","        abs_err_valid = abs_err[valid_mask]\n","\n","        mae = abs_err_valid.mean()\n","\n","        rmse = np.sqrt((abs_err_valid ** 2).mean())\n","        absrel_disp = (abs_err_valid / (np.abs(gt_t[valid_mask]) + 1e-8)).mean()\n","\n","        unc_mean = np.nanmean(var_np[valid_mask])\n","        unc_max  = np.nanmax(var_np[valid_mask])\n","\n","        err_map = abs_err\n","        err_map[~valid_mask] = np.nan\n","        vmax_err = np.nanpercentile(err_map, 95)\n","    else:\n","        mae = rmse = absrel_disp = np.nan\n","        unc_mean = unc_max = np.nan\n","        err_map = np.full_like(pred_np, np.nan, dtype=np.float32)\n","        vmax_err = 1.0\n","\n","    ctx_disp_colors = [disp_to_raft_color_raft_style(f) for f in ctx_np]\n","    gt_color, pred_color = color_gt_and_pred(gt_t, pred_np)\n","\n","    #plotting\n","    n_rows, n_cols = 5, 3\n","    fig, axes = plt.subplots(n_rows, n_cols, figsize=(11, 14))\n","\n","    # Row 1: RGB t-2, t-1, t\n","    for i, ax in enumerate(axes[0]):\n","        ax.imshow(rgb_ctx[i])\n","        ax.set_title([\"RGB t-2\", \"RGB t-1\", \"RGB t\"][i])\n","        ax.axis(\"off\")\n","\n","    # Row 2: Disp t-2, t-1, t\n","    for i, ax in enumerate(axes[1]):\n","        ax.imshow(ctx_disp_colors[i])\n","        ax.set_title([\"Disp t-2\", \"Disp t-1\", \"Disp t\"][i])\n","        ax.axis(\"off\")\n","\n","    # Row 3: RGB t+H*, GT t+H*, Pred t+H*\n","    ax_rf, ax_gt, ax_pred = axes[2]\n","    ax_rf.imshow(rgb_future)\n","    ax_rf.set_title(f\"RGB t+{H_STAR}\")\n","    ax_rf.axis(\"off\")\n","\n","    ax_gt.imshow(gt_color)\n","    ax_gt.set_title(f\"GT t+{H_STAR}\")\n","    ax_gt.axis(\"off\")\n","\n","    ax_pred.imshow(pred_color)\n","    ax_pred.set_title(f\"Pred t+{H_STAR}\")\n","    ax_pred.axis(\"off\")\n","\n","    # Row 4: |Pred-GT|, variance map, blank\n","    ax_err, ax_varmap, ax_dispdiff = axes[3]\n","\n","    # |Disp(t) - Disp(t+H*)|\n","    disp_diff = np.abs(all_disp[t] - gt_t)     # H,W\n","    disp_diff[~valid_mask] = np.nan\n","    vmax_dd = np.nanpercentile(disp_diff, 95) if np.any(valid_mask) else 1.0\n","\n","    im_dd = ax_dispdiff.imshow(disp_diff, cmap=\"coolwarm\", vmin=0, vmax=vmax_dd)\n","    ax_dispdiff.set_title(f\"|Disp(t) - Disp(t+{H_STAR})|\")\n","    ax_dispdiff.axis(\"off\")\n","    fig.colorbar(im_dd, ax=ax_dispdiff, fraction=0.046, pad=0.04)\n","\n","    # Error |Pred - GT|\n","    im_err = ax_err.imshow(err_map, cmap=\"magma\", vmin=0, vmax=vmax_err)\n","    ax_err.set_title(\"|Pred - GT|\")\n","    ax_err.axis(\"off\")\n","    fig.colorbar(im_err, ax=ax_err, fraction=0.046, pad=0.04)\n","\n","    # Variance\n","    vmax_u = np.nanpercentile(var_np[valid_mask], 95) if np.any(valid_mask) else 1.0\n","    im_u = ax_varmap.imshow(var_np, cmap=\"viridis\", vmin=0, vmax=vmax_u)\n","    ax_varmap.set_title(\"Variance σ²\")\n","    ax_varmap.axis(\"off\")\n","    fig.colorbar(im_u, ax=ax_varmap, fraction=0.046, pad=0.04)\n","\n","    # Row 5: Metrics text\n","\n","    for ax in axes[4]:\n","      ax.axis(\"off\")\n","\n","    metrics_text = (\n","        f\"MAE (EPE): {mae:.3f} RMSE: {rmse:.3f} AbsRel-d: {absrel_disp:.3f}  \\n\"\n","        f\"mean σ²: {unc_mean:.2e}  max σ²: {unc_max:.2e}\"\n","    )\n","\n","    axes[4][0].text(\n","        0.01, 0.5, metrics_text,\n","        fontsize=12,\n","        ha=\"left\", va=\"center\",\n","        transform=axes[4][0].transAxes\n","    )\n","\n","    fig.suptitle(\n","    f\"Streaming @ t={t}, horizon={H_STAR} \"\n","    f\"(η={eta_ms:.1f}ms, Δt={dt_ms:.1f}ms, n*={H_STAR}), K={K_SAMPLES}\",\n","    fontsize=14\n","    )\n","\n","    # showing in notebook\n","    # clear_output(wait=True)\n","    # display(fig)\n","\n","    if SHOW_LIVE:\n","        clear_output(wait=True)\n","        display(fig)\n","        plt.pause(0.001)\n","\n","    fig.canvas.draw()\n","    w, h = fig.canvas.get_width_height()\n","    buf = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n","    buf = buf.reshape((h, w, 4))          # [H, W, 4]\n","    frame_img = buf[..., :3]              # drop alpha → [H, W, 3]\n","\n","    # for _ in range(REPEATS):\n","    writer.append_data(frame_img)\n","\n","    plt.close(fig)\n","    time.sleep(SLEEP_SEC)\n","\n","writer.close()\n","print(\"Streaming finished. Video saved to:\", video_path)"],"metadata":{"id":"sjEnuC8jjHXL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765186687660,"user_tz":360,"elapsed":171287,"user":{"displayName":"Pallavi Sharma","userId":"00480827119504929317"}},"outputId":"bbeac428-b7bc-454a-a524-cb2f5a876f87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-838114082.py:23: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n","  turbo = cm.get_cmap(\"turbo\")\n","/tmp/ipython-input-838114082.py:59: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n","  turbo = cm.get_cmap(\"turbo\")\n","WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1100, 1400) to (1104, 1408) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"]},{"output_type":"stream","name":"stdout","text":["Streaming finished. Video saved to: /content/drive/Shareddrives/TissueMotionForecasting/videos/stream_dsdataset_4_kf1_h9.mp4\n"]}]}]}