{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 701,
     "status": "ok",
     "timestamp": 1765094233599,
     "user": {
      "displayName": "Kesav Nagendra",
      "userId": "14572626763742737951"
     },
     "user_tz": 360
    },
    "id": "mi-jWv4v03Uk",
    "outputId": "2cc9e151-f61b-41fd-f21e-d3a2d5893cda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "Using device: cuda\n",
      "TRAIN_ROOT: /content/drive/Shareddrives/TissueMotionForecasting/scared_data/train\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "BASE_DIR = Path(\"/content/drive/Shareddrives/TissueMotionForecasting\")\n",
    "TRAIN_ROOT = BASE_DIR / \"scared_data\" / \"train\"\n",
    "print(\"TRAIN_ROOT:\", TRAIN_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YNRPKyyOzJTW"
   },
   "outputs": [],
   "source": [
    "CROP_H, CROP_W = 256, 320\n",
    "\n",
    "def random_crop_torch(stack, ch, cw):\n",
    "    \"\"\"\n",
    "    stack: [C, H, W] or [C+1, H, W]\n",
    "    returns: cropped stack with same channel dim, spatial ch x cw\n",
    "    \"\"\"\n",
    "    _, H, W = stack.shape\n",
    "    if H <= ch or W <= cw:\n",
    "        return stack\n",
    "    top = np.random.randint(0, H - ch)\n",
    "    left = np.random.randint(0, W - cw)\n",
    "    return stack[:, top:top+ch, left:left+cw]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1765094240982,
     "user": {
      "displayName": "Kesav Nagendra",
      "userId": "14572626763742737951"
     },
     "user_tz": 360
    },
    "id": "7ahQ7ZgSahAk",
    "outputId": "2569734b-297a-4207-da7a-32fcac853cec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DisparityForecastDataset: 7952 samples\n",
      "Total samples: 7952\n",
      "Context shape: torch.Size([3, 256, 320])\n",
      "Target  shape: torch.Size([1, 256, 320])\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_LEN = 3\n",
    "FORECAST_HORIZON = 5\n",
    "DISP_SCALE = 256.0\n",
    "\n",
    "DATASETS_TO_USE = [\"dataset_1\", \"dataset_2\", \"dataset_3\"]\n",
    "KEYFRAME_NAMES  = [f\"keyframe_{i}\" for i in range(1, 6)]\n",
    "\n",
    "\n",
    "class DisparityForecastDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Build (context, target) forecast pairs from RAW disparity PNGs.\n",
    "\n",
    "    - Uses disparity PNGs from:\n",
    "        TRAIN_ROOT/dataset_X/keyframe_Y/data/disparity/*.png\n",
    "    - Ignores colored_*.png\n",
    "    - context: [C,H,W], C = context_len\n",
    "    - target : [1,H,W] at t + forecast_horizon\n",
    "    \"\"\"\n",
    "    def __init__(self, train_root, dataset_names, keyframe_names,\n",
    "                 context_len=3, forecast_horizon=10, scale=256.0):\n",
    "        self.samples = []\n",
    "        self.context_len = context_len\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.scale = scale\n",
    "\n",
    "        for ds_name in dataset_names:\n",
    "            for kf_name in keyframe_names:\n",
    "                disp_dir = train_root / ds_name / kf_name / \"data\" / \"disparity\"\n",
    "                if not disp_dir.exists():\n",
    "                    continue\n",
    "\n",
    "                frame_paths = sorted([\n",
    "                    p for p in disp_dir.glob(\"*.png\")\n",
    "                    if not p.name.startswith(\"colored\")\n",
    "                ])\n",
    "\n",
    "                if len(frame_paths) < context_len + forecast_horizon:\n",
    "                    continue\n",
    "\n",
    "                # slide window: [i-(C-1) ... i] -> target at i+H\n",
    "                for i in range(context_len - 1,\n",
    "                               len(frame_paths) - forecast_horizon):\n",
    "                    ctx_paths = frame_paths[i - (context_len - 1): i + 1]\n",
    "                    tgt_path  = frame_paths[i + forecast_horizon]\n",
    "                    self.samples.append((ctx_paths, tgt_path))\n",
    "\n",
    "        print(f\"DisparityForecastDataset: {len(self.samples)} samples\")\n",
    "\n",
    "    def _load_disp(self, path: Path):\n",
    "        img = Image.open(path).convert(\"I\")\n",
    "        arr = np.array(img, dtype=np.float32)\n",
    "        arr = arr / self.scale\n",
    "        return arr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ctx_paths, tgt_path = self.samples[idx]\n",
    "        ctx_frames = [self._load_disp(p) for p in ctx_paths]  # list of [H,W]\n",
    "        ctx = np.stack(ctx_frames, axis=0)                    # [C,H,W]\n",
    "        tgt = self._load_disp(tgt_path)                       # [H,W]\n",
    "\n",
    "        ctx = torch.from_numpy(ctx.astype(\"float32\"))         # [C,H,W]\n",
    "        tgt = torch.from_numpy(tgt.astype(\"float32\")).unsqueeze(0)  # [1,H,W]\n",
    "\n",
    "        stack = torch.cat([ctx, tgt], dim=0)                  # [C+1,H,W]\n",
    "        stack = random_crop_torch(stack, CROP_H, CROP_W)      # [C+1,ch,cw]\n",
    "        ctx = stack[:-1]                                      # [C,ch,cw]\n",
    "        tgt = stack[-1:].contiguous()                         # [1,ch,cw]\n",
    "\n",
    "        return ctx, tgt\n",
    "\n",
    "\n",
    "dataset = DisparityForecastDataset(\n",
    "    train_root=TRAIN_ROOT,\n",
    "    dataset_names=DATASETS_TO_USE,\n",
    "    keyframe_names=KEYFRAME_NAMES,\n",
    "    context_len=CONTEXT_LEN,\n",
    "    forecast_horizon=FORECAST_HORIZON,\n",
    "    scale=DISP_SCALE,\n",
    ")\n",
    "\n",
    "print(\"Total samples:\", len(dataset))\n",
    "ctx_sample, tgt_sample = dataset[0]\n",
    "print(\"Context shape:\", ctx_sample.shape)\n",
    "print(\"Target  shape:\", tgt_sample.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10036,
     "status": "ok",
     "timestamp": 1765094255533,
     "user": {
      "displayName": "Kesav Nagendra",
      "userId": "14572626763742737951"
     },
     "user_tz": 360
    },
    "id": "NelNotYiblM3",
    "outputId": "76e648a0-0e6f-4d48-f707-9e51b7516cdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 6362, Val samples: 1590\n",
      "ctx_batch: torch.Size([2, 3, 256, 320]) tgt_batch: torch.Size([2, 1, 256, 320])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "VAL_FRACTION = 0.2\n",
    "val_len = int(len(dataset) * VAL_FRACTION)\n",
    "train_len = len(dataset) - val_len\n",
    "\n",
    "train_set, val_set = random_split(dataset, [train_len, val_len])\n",
    "print(f\"Train samples: {train_len}, Val samples: {val_len}\")\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=2, pin_memory= True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=2, pin_memory=True\n",
    ")\n",
    "\n",
    "ctx_batch, tgt_batch = next(iter(train_loader))\n",
    "print(\"ctx_batch:\", ctx_batch.shape, \"tgt_batch:\", tgt_batch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-icmPRMqH_ER"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc1 = DoubleConv(in_channels, 32)\n",
    "        self.enc2 = DoubleConv(32, 64)\n",
    "        self.enc3 = DoubleConv(64, 128)\n",
    "        self.enc4 = DoubleConv(128, 256)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = DoubleConv(256, 512)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec4 = DoubleConv(256 + 256, 256)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec3 = DoubleConv(128 + 128, 128)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec2 = DoubleConv(64 + 64, 64)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.dec1 = DoubleConv(32 + 32, 32)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "\n",
    "        d4 = self.up4(b)\n",
    "        d4 = torch.cat([d4, e4], dim=1)\n",
    "        d4 = self.dec4(d4)\n",
    "\n",
    "        d3 = self.up3(d4)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "\n",
    "        d2 = self.up2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        d1 = self.up1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "\n",
    "        out = self.out_conv(d1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1765094303532,
     "user": {
      "displayName": "Kesav Nagendra",
      "userId": "14572626763742737951"
     },
     "user_tz": 360
    },
    "id": "RLonioCocGlX",
    "outputId": "af9eb897-b3fd-4336-f9a4-6cc50e00f4f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred crop size from loader: H=256, W=320\n",
      "Loaded UNet checkpoint and froze backbone.\n",
      "UNet output shape: torch.Size([2, 1, 256, 320])\n"
     ]
    }
   ],
   "source": [
    "_, C, Hc, Wc = ctx_batch.shape   # ctx_batch: [B,3,H,W]\n",
    "print(f\"Inferred crop size from loader: H={Hc}, W={Wc}\")\n",
    "\n",
    "backbone = UNet(in_channels=3, out_channels=1).to(device)\n",
    "\n",
    "CKPT_PATH = \"/content/drive/Shareddrives/TissueMotionForecasting/models/unet_forecast_kf1to3_7_epochs.pth\"\n",
    "state_dict = torch.load(CKPT_PATH, map_location=device)\n",
    "backbone.load_state_dict(state_dict)\n",
    "backbone.to(device)\n",
    "backbone.eval()\n",
    "\n",
    "for p in backbone.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "print(\"Loaded UNet checkpoint and froze backbone.\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = backbone(ctx_batch.to(device))\n",
    "print(\"UNet output shape:\", out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1765094308166,
     "user": {
      "displayName": "Kesav Nagendra",
      "userId": "14572626763742737951"
     },
     "user_tz": 360
    },
    "id": "9IBXV_XhhPtW",
    "outputId": "9e084d04-26c9-49a7-84af-32903aa4546c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion head params: 0.042681 M\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, num_groups=4):\n",
    "        super().__init__()\n",
    "        g = min(num_groups, out_ch)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(g, out_ch),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(g, out_ch),\n",
    "            nn.SiLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class DiffusionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Much smaller U-Net:\n",
    "      base_channels = 8\n",
    "      input : [B,4,H,W] (x_t, ctx_last, mu, t_channel)\n",
    "      output: [B,1,H,W] (eps_hat)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=4, base_channels=8):\n",
    "        super().__init__()\n",
    "        c = base_channels\n",
    "\n",
    "        # encoder\n",
    "        self.enc1 = ConvBlock(in_channels, c)\n",
    "        self.down1 = nn.Conv2d(c, c, 4, stride=2, padding=1)  # H/2\n",
    "\n",
    "        self.enc2 = ConvBlock(c, c * 2)\n",
    "        self.down2 = nn.Conv2d(c * 2, c * 2, 4, stride=2, padding=1)  # H/4\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck = ConvBlock(c * 2, c * 4)\n",
    "\n",
    "        # decoder\n",
    "        self.up2 = nn.ConvTranspose2d(c * 4, c * 2, 4, stride=2, padding=1)\n",
    "        self.dec2 = ConvBlock(c * 4, c * 2)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(c * 2, c, 4, stride=2, padding=1)\n",
    "        self.dec1 = ConvBlock(c * 2, c)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(c, 1, 1)\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        # x_in: [B,4,H,W]\n",
    "        e1 = self.enc1(x_in)     # [B,c,H,W]\n",
    "        d1 = self.down1(e1)      # [B,c,H/2,W/2]\n",
    "\n",
    "        e2 = self.enc2(d1)       # [B,2c,H/2,W/2]\n",
    "        d2 = self.down2(e2)      # [B,2c,H/4,W/4]\n",
    "\n",
    "        b = self.bottleneck(d2)  # [B,4c,H/4,W/4]\n",
    "\n",
    "        u2 = self.up2(b)         # [B,2c,H/2,W/2]\n",
    "        u2 = torch.cat([u2, e2], dim=1)\n",
    "        u2 = self.dec2(u2)       # [B,2c,H/2,W/2]\n",
    "\n",
    "        u1 = self.up1(u2)        # [B,c,H,W]\n",
    "        u1 = torch.cat([u1, e1], dim=1)\n",
    "        u1 = self.dec1(u1)       # [B,c,H,W]\n",
    "\n",
    "        out = self.out_conv(u1)  # [B,1,H,W]\n",
    "        return out\n",
    "\n",
    "diff_head = DiffusionHead(in_channels=4, base_channels=8).to(device)\n",
    "print(\"Diffusion head params:\",\n",
    "      sum(p.numel() for p in diff_head.parameters()) / 1e6, \"M\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UPYUpDfhSu2"
   },
   "outputs": [],
   "source": [
    "T = 10\n",
    "beta_start, beta_end = 1e-4, 0.02\n",
    "betas = torch.linspace(beta_start, beta_end, T, device=device)\n",
    "alphas = 1.0 - betas\n",
    "alpha_bar = torch.cumprod(alphas, dim=0)\n",
    "\n",
    "print(\"Defined diffusion schedule with T =\", T)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(diff_head.parameters(), lr=3e-4)\n",
    "NUM_DIFF_EPOCHS = 5\n",
    "for epoch in range(1, NUM_DIFF_EPOCHS + 1):\n",
    "    diff_head.train()\n",
    "    running_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for ctx, tgt in train_loader:\n",
    "        ctx = ctx.to(device)   # [1,3,H,W]\n",
    "        tgt = tgt.to(device)   # [1,1,H,W]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mu = backbone(ctx)           # [B,1,H,W]\n",
    "            ctx_last = ctx[:, -1:, :, :]  # # [B,1,H,W]\n",
    "\n",
    "        cond = torch.cat([ctx_last, mu], dim=1)  # [1,2,H,W]\n",
    "\n",
    "        B = tgt.shape[0]\n",
    "        t_idx = torch.randint(0, T, (B,), device=device)\n",
    "        eps = torch.randn_like(tgt)\n",
    "\n",
    "        a_bar = alpha_bar[t_idx].view(B, 1, 1, 1)\n",
    "        x_t = torch.sqrt(a_bar) * tgt + torch.sqrt(1.0 - a_bar) * eps\n",
    "\n",
    "        t_channel = (t_idx.float() / (T - 1)).view(B, 1, 1, 1)\n",
    "        t_channel = t_channel.expand_as(tgt)\n",
    "\n",
    "        x_in = torch.cat([x_t, cond, t_channel], dim=1)  # [1,4,H,W]\n",
    "        eps_hat = diff_head(x_in)\n",
    "\n",
    "        mask = (tgt > 0).float()\n",
    "        sq_err = (eps_hat - eps) ** 2 * mask\n",
    "        loss = sq_err.sum() / (mask.sum() + 1e-8)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    avg_loss = running_loss / max(1, n_batches)\n",
    "    print(f\"[Diffusion] Epoch {epoch:02d} | train noise-MSE(masked): {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1765064001680,
     "user": {
      "displayName": "Kesav Nagendra",
      "userId": "14572626763742737951"
     },
     "user_tz": 360
    },
    "id": "RsvegD-xjiYt",
    "outputId": "4d01ee7d-3aee-4ee6-8edc-78ae6d0abc62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved RAW diffusion head → /content/drive/Shareddrives/TissueMotionForecasting/models/diffusion_head_with_5_epochs.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "RAW_SAVE_PATH = \"/content/drive/Shareddrives/TissueMotionForecasting/models/diffusion_head_with_5_epochs.pth\"\n",
    "\n",
    "torch.save({\n",
    "    \"state_dict\": diff_head.state_dict(),   # raw weights\n",
    "    \"betas\": betas,                         # diffusion schedule\n",
    "    \"alpha_bar\": alpha_bar,\n",
    "}, RAW_SAVE_PATH)\n",
    "\n",
    "print(f\"Saved RAW diffusion head → {RAW_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1765094323251,
     "user": {
      "displayName": "Kesav Nagendra",
      "userId": "14572626763742737951"
     },
     "user_tz": 360
    },
    "id": "MIjkkOwwCS1X",
    "outputId": "8aa0d114-2315-43f9-8bb9-5bee5503be79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded diffusion head from /content/drive/Shareddrives/TissueMotionForecasting/models/diffusion_head_with_15_epochs.pth with T = 10\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "CKPT_PATH = \"/content/drive/Shareddrives/TissueMotionForecasting/models/diffusion_head_with_15_epochs.pth\"\n",
    "\n",
    "ckpt = torch.load(CKPT_PATH, map_location=device)\n",
    "\n",
    "# restore weights\n",
    "diff_head.load_state_dict(ckpt[\"state_dict\"])\n",
    "\n",
    "# restore diffusion schedule\n",
    "betas = ckpt[\"betas\"].to(device)\n",
    "alpha_bar = ckpt[\"alpha_bar\"].to(device)\n",
    "T = betas.shape[0]\n",
    "\n",
    "print(f\"Reloaded diffusion head from {CKPT_PATH} with T = {T}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9593850,
     "status": "ok",
     "timestamp": 1765103944409,
     "user": {
      "displayName": "Kesav Nagendra",
      "userId": "14572626763742737951"
     },
     "user_tz": 360
    },
    "id": "2pZNrqgACpcA",
    "outputId": "63d33ea0-a756-491e-a2e3-a83c08ef72c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing training diffusion head with LR = 0.0003\n",
      "[Diffusion] Extra Epoch 01 | train noise-MSE(masked): 0.7411\n",
      "[Diffusion] Extra Epoch 02 | train noise-MSE(masked): 0.7386\n",
      "[Diffusion] Extra Epoch 03 | train noise-MSE(masked): 0.7247\n",
      "[Diffusion] Extra Epoch 04 | train noise-MSE(masked): 0.7250\n",
      "[Diffusion] Extra Epoch 05 | train noise-MSE(masked): 0.7242\n",
      "[Diffusion] Extra Epoch 06 | train noise-MSE(masked): 0.7221\n",
      "[Diffusion] Extra Epoch 07 | train noise-MSE(masked): 0.7218\n",
      "[Diffusion] Extra Epoch 08 | train noise-MSE(masked): 0.7371\n",
      "[Diffusion] Extra Epoch 09 | train noise-MSE(masked): 0.7146\n",
      "[Diffusion] Extra Epoch 10 | train noise-MSE(masked): 0.7066\n",
      "[Diffusion] Extra Epoch 11 | train noise-MSE(masked): 0.7026\n",
      "[Diffusion] Extra Epoch 12 | train noise-MSE(masked): 0.7082\n",
      "[Diffusion] Extra Epoch 13 | train noise-MSE(masked): 0.7099\n",
      "[Diffusion] Extra Epoch 14 | train noise-MSE(masked): 0.7080\n",
      "[Diffusion] Extra Epoch 15 | train noise-MSE(masked): 0.7030\n",
      "[Diffusion] Extra Epoch 16 | train noise-MSE(masked): 0.6983\n",
      "[Diffusion] Extra Epoch 17 | train noise-MSE(masked): 0.7028\n",
      "[Diffusion] Extra Epoch 18 | train noise-MSE(masked): 0.7013\n",
      "[Diffusion] Extra Epoch 19 | train noise-MSE(masked): 0.7226\n",
      "[Diffusion] Extra Epoch 20 | train noise-MSE(masked): 0.6990\n"
     ]
    }
   ],
   "source": [
    "LR = 3e-4\n",
    "optimizer = torch.optim.Adam(diff_head.parameters(), lr=LR)\n",
    "print(\"Continuing training diffusion head with LR =\", LR)\n",
    "\n",
    "NUM_EXTRA_EPOCHS = 20\n",
    "\n",
    "for epoch in range(1, NUM_EXTRA_EPOCHS + 1):\n",
    "    diff_head.train()\n",
    "    running_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for ctx, tgt in train_loader:\n",
    "        ctx = ctx.to(device)   # [B,3,H,W]\n",
    "        tgt = tgt.to(device)   # [B,1,H,W]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            mu = backbone(ctx)           # [B,1,H,W]\n",
    "            ctx_last = ctx[:, -1:, :, :] # [B,1,H,W]\n",
    "\n",
    "        cond = torch.cat([ctx_last, mu], dim=1)  # [B,2,H,W]\n",
    "\n",
    "        B = tgt.shape[0]\n",
    "        t_idx = torch.randint(0, T, (B,), device=device)\n",
    "        eps = torch.randn_like(tgt)\n",
    "\n",
    "        a_bar = alpha_bar[t_idx].view(B, 1, 1, 1)\n",
    "        x_t = torch.sqrt(a_bar) * tgt + torch.sqrt(1.0 - a_bar) * eps\n",
    "\n",
    "        t_channel = (t_idx.float() / (T - 1)).view(B, 1, 1, 1)\n",
    "        t_channel = t_channel.expand_as(tgt)\n",
    "\n",
    "        x_in = torch.cat([x_t, cond, t_channel], dim=1)\n",
    "        eps_hat = diff_head(x_in)\n",
    "\n",
    "        mask = (tgt > 0).float()\n",
    "        sq_err = (eps_hat - eps) ** 2 * mask\n",
    "        loss = sq_err.sum() / (mask.sum() + 1e-8)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(diff_head.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    avg_loss = running_loss / max(1, n_batches)\n",
    "    print(f\"[Diffusion] Extra Epoch {epoch:02d} | train noise-MSE(masked): {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1765103944418,
     "user": {
      "displayName": "Kesav Nagendra",
      "userId": "14572626763742737951"
     },
     "user_tz": 360
    },
    "id": "VR2O8Fv1CsCI",
    "outputId": "7aa7c863-1b92-4ebe-e794-abd709791752"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved updated diffusion head → /content/drive/Shareddrives/TissueMotionForecasting/models/diffusion_head_with_35_epochs.pth\n"
     ]
    }
   ],
   "source": [
    "NEW_SAVE_PATH = \"/content/drive/Shareddrives/TissueMotionForecasting/models/diffusion_head_with_35_epochs.pth\"\n",
    "\n",
    "torch.save({\n",
    "    \"state_dict\": diff_head.state_dict(),\n",
    "    \"betas\": betas,\n",
    "    \"alpha_bar\": alpha_bar,\n",
    "}, NEW_SAVE_PATH)\n",
    "\n",
    "print(f\"Saved updated diffusion head → {NEW_SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 855,
     "status": "ok",
     "timestamp": 1765089933110,
     "user": {
      "displayName": "Fnu Pallavi Sharma",
      "userId": "12282999598869110389"
     },
     "user_tz": 360
    },
    "id": "Z4leWNsdjtBy",
    "outputId": "5c52eb25-17b1-4df4-d35e-8dec4f2e76ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded diffusion head from /content/drive/Shareddrives/TissueMotionForecasting/models/diffusion_head_with_15_epochs.pth\n",
      "T (num timesteps) = 10\n"
     ]
    }
   ],
   "source": [
    "DIFF_CKPT_PATH = \"/content/drive/Shareddrives/TissueMotionForecasting/models/diffusion_head_with_35_epochs.pth\"\n",
    "\n",
    "ckpt = torch.load(DIFF_CKPT_PATH, map_location=device)\n",
    "\n",
    "# recreate the diffusion head with the same architecture\n",
    "diff_head = DiffusionHead(in_channels=4, base_channels=8).to(device)\n",
    "diff_head.load_state_dict(ckpt[\"state_dict\"])\n",
    "diff_head.eval()\n",
    "\n",
    "# restore schedule from checkpoint\n",
    "betas = ckpt[\"betas\"].to(device)\n",
    "alpha_bar = ckpt[\"alpha_bar\"].to(device)\n",
    "T = betas.shape[0]\n",
    "\n",
    "print(f\"Loaded diffusion head from {DIFF_CKPT_PATH}\")\n",
    "print(f\"T (num timesteps) = {T}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
