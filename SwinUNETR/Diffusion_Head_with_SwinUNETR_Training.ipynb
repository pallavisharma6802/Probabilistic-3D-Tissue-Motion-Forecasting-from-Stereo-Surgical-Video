{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install -q \"monai[all]\" nibabel einops"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZeiZ6abMb9ym","executionInfo":{"status":"ok","timestamp":1765047890076,"user_tz":360,"elapsed":71353,"user":{"displayName":"Fnu Pallavi Sharma","userId":"12282999598869110389"}},"outputId":"05fb9f86-6026-44f4-b5d0-86f85c47d697"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.5/266.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.5/28.5 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.4/299.4 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.9/193.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.1/284.1 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m155.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.9/753.9 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pytensor 2.35.1 requires filelock>=3.15, but you have filelock 3.11.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mi-jWv4v03Uk","outputId":"b2274b10-cf7a-43d0-8c31-7d3e2605c982","executionInfo":{"status":"ok","timestamp":1765047943578,"user_tz":360,"elapsed":53498,"user":{"displayName":"Fnu Pallavi Sharma","userId":"12282999598869110389"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["<frozen importlib._bootstrap_external>:1301: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n"]},{"output_type":"stream","name":"stdout","text":["Using device: cpu\n","TRAIN_ROOT: /content/drive/Shareddrives/TissueMotionForecasting/scared_data/train\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","from pathlib import Path\n","\n","import numpy as np\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from monai.networks.nets import SwinUNETR\n","\n","device = torch.device(\"cpu\")\n","print(\"Using device:\", device)\n","\n","BASE_DIR = Path(\"/content/drive/Shareddrives/TissueMotionForecasting\")\n","TRAIN_ROOT = BASE_DIR / \"scared_data\" / \"train\"\n","print(\"TRAIN_ROOT:\", TRAIN_ROOT)\n"]},{"cell_type":"code","source":["CROP_H, CROP_W = 256, 320\n","\n","def random_crop_torch(stack, ch, cw):\n","    \"\"\"\n","    stack: [C, H, W] or [C+1, H, W]\n","    returns: cropped stack with same channel dim, spatial ch x cw\n","    \"\"\"\n","    _, H, W = stack.shape\n","    if H <= ch or W <= cw:\n","        return stack\n","    top = np.random.randint(0, H - ch)\n","    left = np.random.randint(0, W - cw)\n","    return stack[:, top:top+ch, left:left+cw]\n"],"metadata":{"id":"YNRPKyyOzJTW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CONTEXT_LEN = 3\n","FORECAST_HORIZON = 10\n","DISP_SCALE = 256.0\n","\n","DATASETS_TO_USE = [\"dataset_1\", \"dataset_2\", \"dataset_3\"]\n","KEYFRAME_NAMES  = [f\"keyframe_{i}\" for i in range(1, 6)]  # 1..5\n","\n","\n","class DisparityForecastDataset(Dataset):\n","    \"\"\"\n","    Build (context, target) forecast pairs from RAW disparity PNGs.\n","\n","    - Uses disparity PNGs from:\n","        TRAIN_ROOT/dataset_X/keyframe_Y/data/disparity/*.png\n","    - Ignores colored_*.png\n","    - context: [C,H,W], C = context_len\n","    - target : [1,H,W] at t + forecast_horizon\n","    \"\"\"\n","    def __init__(self, train_root, dataset_names, keyframe_names,\n","                 context_len=3, forecast_horizon=10, scale=256.0):\n","        self.samples = []\n","        self.context_len = context_len\n","        self.forecast_horizon = forecast_horizon\n","        self.scale = scale\n","\n","        for ds_name in dataset_names:\n","            for kf_name in keyframe_names:\n","                disp_dir = train_root / ds_name / kf_name / \"data\" / \"disparity\"\n","                if not disp_dir.exists():\n","                    continue\n","\n","                frame_paths = sorted([\n","                    p for p in disp_dir.glob(\"*.png\")\n","                    if not p.name.startswith(\"colored\")\n","                ])\n","\n","                if len(frame_paths) < context_len + forecast_horizon:\n","                    continue\n","\n","\n","                for i in range(context_len - 1,\n","                               len(frame_paths) - forecast_horizon):\n","                    ctx_paths = frame_paths[i - (context_len - 1): i + 1]\n","                    tgt_path  = frame_paths[i + forecast_horizon]\n","                    self.samples.append((ctx_paths, tgt_path))\n","\n","        print(f\"DisparityForecastDataset: {len(self.samples)} samples\")\n","\n","    def _load_disp(self, path: Path):\n","        img = Image.open(path).convert(\"I\")\n","        arr = np.array(img, dtype=np.float32)\n","        arr = arr / self.scale\n","        return arr\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        ctx_paths, tgt_path = self.samples[idx]\n","        ctx_frames = [self._load_disp(p) for p in ctx_paths]  # list of [H,W]\n","        ctx = np.stack(ctx_frames, axis=0)                    # [C,H,W]\n","        tgt = self._load_disp(tgt_path)                       # [H,W]\n","\n","        ctx = torch.from_numpy(ctx.astype(\"float32\"))         # [C,H,W]\n","        tgt = torch.from_numpy(tgt.astype(\"float32\")).unsqueeze(0)  # [1,H,W]\n","\n","        stack = torch.cat([ctx, tgt], dim=0)                  # [C+1,H,W]\n","        stack = random_crop_torch(stack, CROP_H, CROP_W)      # [C+1,ch,cw]\n","        ctx = stack[:-1]                                      # [C,ch,cw]\n","        tgt = stack[-1:].contiguous()                         # [1,ch,cw]\n","\n","        return ctx, tgt\n","\n","\n","dataset = DisparityForecastDataset(\n","    train_root=TRAIN_ROOT,\n","    dataset_names=DATASETS_TO_USE,\n","    keyframe_names=KEYFRAME_NAMES,\n","    context_len=CONTEXT_LEN,\n","    forecast_horizon=FORECAST_HORIZON,\n","    scale=DISP_SCALE,\n",")\n","\n","print(\"Total samples:\", len(dataset))\n","ctx_sample, tgt_sample = dataset[0]\n","print(\"Context shape:\", ctx_sample.shape)\n","print(\"Target  shape:\", tgt_sample.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ahQ7ZgSahAk","executionInfo":{"status":"ok","timestamp":1765006270266,"user_tz":360,"elapsed":70168,"user":{"displayName":"pallavi sharma","userId":"07344016866799049195"}},"outputId":"e4a1f240-819f-4ba1-eff9-a672266a1cd0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DisparityForecastDataset: 7902 samples\n","Total samples: 7902\n","Context shape: torch.Size([3, 1024, 1280])\n","Target  shape: torch.Size([1, 1024, 1280])\n"]}]},{"cell_type":"code","source":["from torch.utils.data import random_split, DataLoader\n","\n","VAL_FRACTION = 0.2\n","val_len = int(len(dataset) * VAL_FRACTION)\n","train_len = len(dataset) - val_len\n","\n","train_set, val_set = random_split(dataset, [train_len, val_len])\n","print(f\"Train samples: {train_len}, Val samples: {val_len}\")\n","\n","BATCH_SIZE = 1\n","\n","train_loader = DataLoader(\n","    train_set, batch_size=BATCH_SIZE, shuffle=True,\n","    num_workers=2, pin_memory=True\n",")\n","val_loader = DataLoader(\n","    val_set, batch_size=BATCH_SIZE, shuffle=False,\n","    num_workers=2, pin_memory=True\n",")\n","\n","ctx_batch, tgt_batch = next(iter(train_loader))\n","print(\"ctx_batch:\", ctx_batch.shape, \"tgt_batch:\", tgt_batch.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NelNotYiblM3","executionInfo":{"status":"ok","timestamp":1765006279331,"user_tz":360,"elapsed":9062,"user":{"displayName":"pallavi sharma","userId":"07344016866799049195"}},"outputId":"baff10a2-ac4a-49e3-de01-ffb0cbd2c33b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train samples: 6322, Val samples: 1580\n"]},{"output_type":"stream","name":"stderr","text":["'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n"]},{"output_type":"stream","name":"stdout","text":["ctx_batch: torch.Size([1, 3, 1024, 1280]) tgt_batch: torch.Size([1, 1, 1024, 1280])\n"]}]},{"cell_type":"code","source":["\n","_, C, Hc, Wc = ctx_batch.shape\n","print(f\"Inferred img_size from loader: H={Hc}, W={Wc}\")\n","\n","FEATURE_SIZE = 48\n","\n","swin_unetr = SwinUNETR(\n","    in_channels=3,\n","    out_channels=1,\n","    feature_size=FEATURE_SIZE,\n","    spatial_dims=2,\n","    use_checkpoint=True,\n",").to(device)\n","\n","\n","CKPT_PATH = \"/content/drive/Shareddrives/TissueMotionForecasting/models/swin_unetr_forecast.pth\"\n","state_dict = torch.load(CKPT_PATH, map_location=device)\n","swin_unetr.load_state_dict(state_dict)\n","swin_unetr.to(device)\n","swin_unetr.eval()\n","\n","for p in swin_unetr.parameters():\n","    p.requires_grad = False\n","\n","print(\"Loaded Swin-UNETR checkpoint and froze backbone.\")\n","\n","with torch.no_grad():\n","    out = swin_unetr(ctx_batch.to(device))\n","print(\"Swin-UNETR output shape:\", out.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RLonioCocGlX","executionInfo":{"status":"ok","timestamp":1765006513837,"user_tz":360,"elapsed":14809,"user":{"displayName":"pallavi sharma","userId":"07344016866799049195"}},"outputId":"6400a262-f984-4b48-8049-96ea5fa9fc45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Inferred img_size from loader: H=1024, W=1280\n","Loaded Swin-UNETR checkpoint and froze backbone.\n","Swin-UNETR output shape: torch.Size([1, 1, 1024, 1280])\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class ConvBlock(nn.Module):\n","    def __init__(self, in_ch, out_ch, num_groups=4):\n","        super().__init__()\n","        g = min(num_groups, out_ch)\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n","            nn.GroupNorm(g, out_ch),\n","            nn.SiLU(),\n","            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n","            nn.GroupNorm(g, out_ch),\n","            nn.SiLU(),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class DiffusionHead(nn.Module):\n","    \"\"\"\n","    Much smaller U-Net:\n","      base_channels = 8\n","      input : [B,4,H,W] (x_t, ctx_last, mu, t_channel)\n","      output: [B,1,H,W] (eps_hat)\n","    \"\"\"\n","    def __init__(self, in_channels=4, base_channels=8):\n","        super().__init__()\n","        c = base_channels\n","\n","        # encoder\n","        self.enc1 = ConvBlock(in_channels, c)\n","        self.down1 = nn.Conv2d(c, c, 4, stride=2, padding=1)  # H/2\n","\n","        self.enc2 = ConvBlock(c, c * 2)\n","        self.down2 = nn.Conv2d(c * 2, c * 2, 4, stride=2, padding=1)  # H/4\n","\n","        # bottleneck\n","        self.bottleneck = ConvBlock(c * 2, c * 4)\n","\n","        # decoder\n","        self.up2 = nn.ConvTranspose2d(c * 4, c * 2, 4, stride=2, padding=1)\n","        self.dec2 = ConvBlock(c * 4, c * 2)\n","\n","        self.up1 = nn.ConvTranspose2d(c * 2, c, 4, stride=2, padding=1)\n","        self.dec1 = ConvBlock(c * 2, c)\n","\n","        self.out_conv = nn.Conv2d(c, 1, 1)\n","\n","    def forward(self, x_in):\n","        # x_in: [B,4,H,W]\n","        e1 = self.enc1(x_in)     # [B,c,H,W]\n","        d1 = self.down1(e1)      # [B,c,H/2,W/2]\n","\n","        e2 = self.enc2(d1)       # [B,2c,H/2,W/2]\n","        d2 = self.down2(e2)      # [B,2c,H/4,W/4]\n","\n","        b = self.bottleneck(d2)  # [B,4c,H/4,W/4]\n","\n","        u2 = self.up2(b)         # [B,2c,H/2,W/2]\n","        u2 = torch.cat([u2, e2], dim=1)\n","        u2 = self.dec2(u2)       # [B,2c,H/2,W/2]\n","\n","        u1 = self.up1(u2)        # [B,c,H,W]\n","        u1 = torch.cat([u1, e1], dim=1)\n","        u1 = self.dec1(u1)       # [B,c,H,W]\n","\n","        out = self.out_conv(u1)  # [B,1,H,W]\n","        return out\n","\n","diff_head = DiffusionHead(in_channels=4, base_channels=8).to(device)\n","print(\"Diffusion head params:\",\n","      sum(p.numel() for p in diff_head.parameters()) / 1e6, \"M\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9IBXV_XhhPtW","executionInfo":{"status":"ok","timestamp":1765006535450,"user_tz":360,"elapsed":19,"user":{"displayName":"pallavi sharma","userId":"07344016866799049195"}},"outputId":"08601672-3193-44ef-fee0-ef50a3fbb1e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Diffusion head params: 0.042681 M\n"]}]},{"cell_type":"code","source":["T = 10\n","beta_start, beta_end = 1e-4, 0.02\n","betas = torch.linspace(beta_start, beta_end, T, device=device)\n","alphas = 1.0 - betas\n","alpha_bar = torch.cumprod(alphas, dim=0)\n","\n","print(\"Defined diffusion schedule with T =\", T)\n","\n","optimizer = torch.optim.Adam(diff_head.parameters(), lr=1e-4)\n","NUM_DIFF_EPOCHS = 1\n","\n","for epoch in range(1, NUM_DIFF_EPOCHS + 1):\n","    diff_head.train()\n","    running_loss = 0.0\n","    n_batches = 0\n","\n","    for ctx, tgt in train_loader:\n","        ctx = ctx.to(device)   # [1,3,H,W]\n","        tgt = tgt.to(device)   # [1,1,H,W]\n","\n","        with torch.no_grad():\n","            mu = swin_unetr(ctx)          # [1,1,H,W]\n","            ctx_last = ctx[:, -1:, :, :]  # [1,1,H,W]\n","\n","        cond = torch.cat([ctx_last, mu], dim=1)  # [1,2,H,W]\n","\n","        B = tgt.shape[0]\n","        t_idx = torch.randint(0, T, (B,), device=device)\n","        eps = torch.randn_like(tgt)\n","\n","        a_bar = alpha_bar[t_idx].view(B, 1, 1, 1)\n","        x_t = torch.sqrt(a_bar) * tgt + torch.sqrt(1.0 - a_bar) * eps\n","\n","        t_channel = (t_idx.float() / (T - 1)).view(B, 1, 1, 1)\n","        t_channel = t_channel.expand_as(tgt)\n","\n","        x_in = torch.cat([x_t, cond, t_channel], dim=1)  # [1,4,H,W]\n","        eps_hat = diff_head(x_in)\n","\n","        mask = (tgt > 0).float()\n","        sq_err = (eps_hat - eps) ** 2 * mask\n","        loss = sq_err.sum() / (mask.sum() + 1e-8)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        n_batches += 1\n","\n","    avg_loss = running_loss / max(1, n_batches)\n","    print(f\"[Diffusion] Epoch {epoch:02d} | train noise-MSE(masked): {avg_loss:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0UPYUpDfhSu2","outputId":"e8fa3915-9e7d-493f-b90f-80deca3b8fd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Defined diffusion schedule with T = 20\n"]}]}]}